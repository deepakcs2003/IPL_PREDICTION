{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3590e0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy: 0.8564356435643564\n",
      "\n",
      "âœ… Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87     12186\n",
      "           1       0.82      0.85      0.84      9226\n",
      "\n",
      "    accuracy                           0.86     21412\n",
      "   macro avg       0.85      0.86      0.85     21412\n",
      "weighted avg       0.86      0.86      0.86     21412\n",
      "\n",
      "âœ… Confusion Matrix:\n",
      " [[10528  1658]\n",
      " [ 1416  7810]]\n",
      "ðŸ”® Prediction Probability (sample): [[0.97402916 0.02597084]]\n",
      "ðŸ’¾ Model saved as 'ipl_win_predictor_v2.pkl'\n"
     ]
    }
   ],
   "source": [
    "# ===================== 1. Install & Import Libraries =====================\n",
    "# Uncomment if needed:\n",
    "# !pip install xgboost\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# ===================== 2. Load CSV Files =====================\n",
    "match = pd.read_csv('matches.csv')\n",
    "delivery = pd.read_csv('deliveries.csv')\n",
    "\n",
    "# ===================== 3. Replace old team names =====================\n",
    "team_map = {\n",
    "    'Delhi Daredevils': 'Delhi Capitals',\n",
    "    'Deccan Chargers': 'Sunrisers Hyderabad',\n",
    "    'Gujarat Lions': 'Gujarat Titans',\n",
    "    'Kings XI Punjab': 'Punjab Kings'\n",
    "}\n",
    "match.replace({'team1': team_map, 'team2': team_map, 'winner': team_map}, inplace=True)\n",
    "\n",
    "# ===================== 4. Filter consistent teams =====================\n",
    "teams = [\n",
    "    \"Chennai Super Kings\", \"Mumbai Indians\", \"Royal Challengers Bangalore\",\n",
    "    \"Kolkata Knight Riders\", \"Sunrisers Hyderabad\", \"Delhi Capitals\",\n",
    "    \"Rajasthan Royals\", \"Punjab Kings\", \"Lucknow Super Giants\", \"Gujarat Titans\"\n",
    "]\n",
    "match = match[match['team1'].isin(teams) & match['team2'].isin(teams)]\n",
    "\n",
    "# ===================== 5. First Innings Total =====================\n",
    "first_innings_score = delivery.groupby(['match_id', 'inning'])['total_runs'].sum().reset_index()\n",
    "first_innings_score = first_innings_score[first_innings_score['inning'] == 1]\n",
    "match = match.merge(first_innings_score[['match_id', 'total_runs']], left_on='id', right_on='match_id', how='left')\n",
    "\n",
    "# ===================== 6. Filter Second Innings =====================\n",
    "delivery = delivery[delivery['inning'] == 2]\n",
    "\n",
    "# Merge with match details\n",
    "match_data = match[['id', 'city', 'winner', 'total_runs']]\n",
    "delivery = delivery.merge(match_data, left_on='match_id', right_on='id')\n",
    "\n",
    "# ===================== 7. Compute Features =====================\n",
    "# Current score as cumulative total_runs_x for second innings deliveries\n",
    "delivery['current_score'] = delivery.groupby('match_id')['total_runs_x'].cumsum()\n",
    "\n",
    "# Run left and balls left\n",
    "delivery['run_left'] = delivery['total_runs_y'] - delivery['current_score']\n",
    "delivery['ball_number'] = (delivery['over'] - 1) * 6 + delivery['ball']\n",
    "delivery['balls_left'] = 120 - delivery['ball_number']\n",
    "\n",
    "# Wickets left\n",
    "delivery['wicket'] = delivery['dismissal_kind'].notnull().astype(int)\n",
    "delivery['wickets'] = 10 - delivery.groupby('match_id')['wicket'].cumsum()\n",
    "\n",
    "# CRR and RRR with protection against division by zero\n",
    "delivery['crr'] = delivery['current_score'] * 6 / (delivery['ball_number'])\n",
    "delivery['rrr'] = delivery['run_left'] * 6 / (delivery['balls_left'])\n",
    "\n",
    "# Replace infinite and NaN values resulting from division by zero or invalid data\n",
    "delivery.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Result (1 if batting team wins, 0 otherwise)\n",
    "delivery['result'] = (delivery['batting_team'] == delivery['winner']).astype(int)\n",
    "\n",
    "# ===================== 8. Select Final Data =====================\n",
    "final_data = delivery[['batting_team', 'bowling_team', 'city',\n",
    "                       'run_left', 'balls_left', 'wickets',\n",
    "                       'crr', 'rrr', 'result']]\n",
    "\n",
    "# Drop NaNs safely by re-assigning to avoid SettingWithCopyWarning\n",
    "final_data = final_data.dropna().reset_index(drop=True)\n",
    "\n",
    "# Shuffle dataset\n",
    "final_data = final_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# ===================== 9. Train/Test Split =====================\n",
    "X = final_data.drop('result', axis=1)\n",
    "y = final_data['result']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ===================== 10. Create Pipeline =====================\n",
    "ct = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'), ['batting_team', 'bowling_team', 'city']),\n",
    "    ('scale', StandardScaler(), ['run_left', 'balls_left', 'wickets', 'crr', 'rrr'])\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessing', ct),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42, solver='liblinear'))\n",
    "])\n",
    "\n",
    "# ===================== 11. Train Model =====================\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ===================== 12. Evaluate Model =====================\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"âœ… Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nâœ… Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"âœ… Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ===================== 13. Make Single Prediction =====================\n",
    "print(\"ðŸ”® Prediction Probability (sample):\", pipeline.predict_proba(X_test.iloc[[0]]))\n",
    "\n",
    "# ===================== 14. Save Model =====================\n",
    "with open('ipl_win_predictor_v2.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline, f)\n",
    "print(\"ðŸ’¾ Model saved as 'ipl_win_predictor_v2.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f25ba7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e060d9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42318165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
